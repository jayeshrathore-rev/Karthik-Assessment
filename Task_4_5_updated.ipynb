{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "#  Load property info from the 'Property & Alias Info.xlsx' file\n",
    "property_info = pd.read_excel('Property & Alias Info.xlsx', sheet_name='PROPERTY INFO')\n",
    "property_info = property_info[['PID']]  # Assuming 'PID' is the column for Property ID\n",
    "property_info.rename(columns={'PID': 'Property ID'}, inplace=True)\n",
    "\n",
    "# Load alias info from the 'ALIAS INFO' sheet\n",
    "alias_info = pd.read_excel('Property & Alias Info.xlsx', sheet_name='ALIAS INFO')\n",
    " \n",
    "alias_info.rename(columns={'#': 'Alias ID'}, inplace=True) \n",
    "\n",
    "# Step 4: Generate a full Cartesian product (many-to-many) of all Property IDs and Alias IDs\n",
    "property_alias_combinations = pd.merge(\n",
    "    pd.DataFrame({'Property ID': property_info['Property ID'].unique()}),\n",
    "    pd.DataFrame({'Alias ID': alias_info['Alias ID'].unique()}),\n",
    "    how='cross'  # This creates the full combination of each Property ID with each Alias ID\n",
    ")\n",
    "\n",
    "merged_data = pd.read_csv('Merged_Follow_Up_Data.csv')\n",
    "\n",
    "combined_df = pd.merge(property_alias_combinations, merged_data, how='outer' , on=['Alias ID', 'Property ID'])\n",
    "\n",
    "combined_df.to_csv('Combined Data.csv' , index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classified follow-up data has been generated successfully.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def contains_keywords(content, keywords):\n",
    "    # Create a regex pattern that combines all keywords, allowing for case-insensitive matches\n",
    "    pattern = r'\\b(?:' + '|'.join(map(re.escape, keywords)) + r')\\b'\n",
    "    return bool(re.search(pattern, content, re.IGNORECASE))\n",
    "\n",
    "def classify_follow_up(row):\n",
    "    if pd.isna(row['Summary of content']) or row['Summary of content'].strip() == '':\n",
    "        # If the content is empty, return the row without further processing\n",
    "        row['Tour Confirmation'] = None\n",
    "        row['Booking Link'] = None\n",
    "        row['Requests Tour Booking'] = None\n",
    "        row['Contains Pictures'] = None\n",
    "        row['Personalized or Generalized'] = None\n",
    "        return row\n",
    "    \n",
    "    content = row['Summary of content'].lower() if pd.notna(row['Summary of content']) else ''\n",
    "    attachments = row['Attachments'] if pd.notna(row['Attachments']) else ''\n",
    "\n",
    "    # Check for tour confirmation using regex\n",
    "    tour_confirmation_keywords = [\n",
    "    'tour confirmation',\n",
    "    'confirmed your tour',\n",
    "    'tour is confirmed',\n",
    "    'tour is booked',\n",
    "    'appointment tour',\n",
    "    'appointment is confirmed',\n",
    "    'tour reservation',\n",
    "    'tour has been confirmed',\n",
    "    'confirmation for your tour',\n",
    "    'confirmed your tour',\n",
    "    'your visit'\n",
    "]\n",
    "    row['Tour Confirmation'] = 'Yes' if contains_keywords(content, tour_confirmation_keywords) else 'No'\n",
    "\n",
    "    # Check for Booking Link\n",
    "    booking_link_keywords = [\n",
    "    'booking',\n",
    "    'schedule',\n",
    "    'book',\n",
    "    'tour',\n",
    "    'reservation',\n",
    "    'reserve'\n",
    "    ]\n",
    "    booking_link_pattern = r'(http[s]?://\\S+)'  # Regex to identify URLs\n",
    "    row['Booking Link'] = 'Yes' if contains_keywords(content, booking_link_keywords) and re.search(booking_link_pattern, content) else 'No'\n",
    "\n",
    "    # Check for Requests Tour Booking\n",
    "    request_tour_keywords = [\n",
    "    'booking a tour',\n",
    "    'schedule a tour',\n",
    "    'book a tour'\n",
    "    'reserve a tour',\n",
    "    'request a tour',\n",
    "    'arrange a tour'\n",
    "]\n",
    "    row['Requests Tour Booking'] = 'Yes' if contains_keywords(content, request_tour_keywords) else 'No'\n",
    "\n",
    "    # Contains Pictures\n",
    "    picture_filetypes = ['.jpg', '.jpeg', '.png', '.gif' , '.webp']\n",
    "    row['Contains Pictures'] = 'Yes' if any(ext in attachments.lower() for ext in picture_filetypes) else 'No'\n",
    "\n",
    "    # Check for alias name\n",
    "    if pd.notna(row['Alias ID']):\n",
    "        alias_row = alias_info.loc[alias_info['Alias ID'] == row['Alias ID']]\n",
    "        \n",
    "        if not alias_row.empty:\n",
    "            alias_name = alias_row['ALIAS NAME'].values[0]\n",
    "            # Split the alias name into substrings and ignore common words like \"or\"\n",
    "            substrings = [word for word in alias_name.lower().split() if word not in ['or']]\n",
    "            \n",
    "            # Check if any substring is in the content\n",
    "            if any(substring in content.lower() for substring in substrings):\n",
    "                row['Personalized or Generalized'] = 'Personalized'\n",
    "            else:\n",
    "                row['Personalized or Generalized'] = 'Generalized'\n",
    "        else:\n",
    "            row['Personalized or Generalized'] = 'Generalized'\n",
    "    else:\n",
    "        row['Personalized or Generalized'] = 'Generalized'\n",
    "\n",
    "    return row\n",
    "\n",
    "# Apply the classification to the follow-up data\n",
    "classified_follow_ups = combined_df.apply(lambda row: classify_follow_up(row), axis=1)\n",
    "\n",
    "classified_follow_ups['ID'] = range(1 , len(classified_follow_ups) + 1\n",
    "                                    )\n",
    "# Save the classified follow-up data\n",
    "classified_follow_ups.to_csv('Classified_Follow_Up_Data_V2.csv', index=False)\n",
    "\n",
    "print(\"Classified follow-up data has been generated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
